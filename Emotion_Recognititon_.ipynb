{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzxO4IWffCznAUrVcRKAGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shailja12326646/AI_AGENTS/blob/main/Emotion_Recognititon_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbV-X4kcjW94"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path=\"/content/archive (10).zip\""
      ],
      "metadata": {
        "id": "KjZ7s49Zrxfo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file_name):\n",
        "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "        mfcc=librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n",
        "        mfcc_scaled=np.mean(mfcc.T,axis=0)\n",
        "        return mfcc_scaled"
      ],
      "metadata": {
        "id": "KaqIB7x5tDRf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "mpXQrJUOtTS4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for actor in os.listdir(data_path):\n",
        "  path=os.path.join(data_path,actor)\n",
        "  for file in os.listdir(path):\n",
        "    file_path=os.path.join(path,file)\n",
        "    print(file_path)"
      ],
      "metadata": {
        "id": "909gj3fItyw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/archive (10).zip\"\n",
        "extract_path = \"/content/data/ravdess/\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extracted to:\", extract_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFnqHxyjz-9e",
        "outputId": "f0008e13-4759-4fa0-e556-5679f908883d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted to: /content/data/ravdess/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "90b8pSe10FgK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "    mfcc_mean = np.mean(mfcc.T, axis=0)\n",
        "    return mfcc_mean\n"
      ],
      "metadata": {
        "id": "zjHzmZPk0Y6H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_map = {\n",
        "    '01': 'neutral',\n",
        "    '02': 'calm',\n",
        "    '03': 'happy',\n",
        "    '04': 'sad',\n",
        "    '05': 'angry',\n",
        "    '06': 'fearful',\n",
        "    '07': 'disgust',\n",
        "    '08': 'surprised'\n",
        "}\n"
      ],
      "metadata": {
        "id": "vrJ4lBGF0a83"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "dataset_path = \"/content/data/ravdess\"\n",
        "\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if file.endswith(\".wav\"):\n",
        "            file_path = os.path.join(root, file)\n",
        "            mfcc_features = extract_mfcc(file_path)\n",
        "            parts = file.split(\"-\")\n",
        "            emotion_code = parts[2]\n",
        "            emotion_label = emotion_map.get(emotion_code)\n",
        "\n",
        "            all_features.append(mfcc_features)\n",
        "            all_labels.append(emotion_label)\n"
      ],
      "metadata": {
        "id": "WA50bX240dNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(all_features)\n",
        "y = np.array(all_labels)\n",
        "\n",
        "print(\"Feature shape:\", X.shape)\n",
        "print(\"Labels:\", y[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CJAmaFb0mrz",
        "outputId": "7c6d1be4-c524-4668-f434-6ae5817162ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shape: (2880, 13)\n",
            "Labels: ['happy' 'sad' 'calm' 'disgust' 'neutral' 'fearful' 'surprised' 'calm'\n",
            " 'fearful' 'surprised']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "FKTMpEcT1AS7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKJB9pcH1E3s",
        "outputId": "f8bcf52a-c2e7-41ca-da8d-c5d7ed6004f4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9131944444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(file_path):\n",
        "    # MFCC features\n",
        "    features = extract_mfcc(file_path)\n",
        "    features = features.reshape(1, -1)\n",
        "\n",
        "\n",
        "    encoded_pred = model.predict(features)[0]\n",
        "    prediction = le.inverse_transform([encoded_pred])[0]\n",
        "\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "9lEcJFmw1Hhd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the audio  with a generated audio from the user\n",
        "file_path = \"/content/WhatsApp Audio 2025-12-09 at 9.48.26 PM.mp4\"\n",
        "emotion = predict_emotion(file_path)\n",
        "print(\"Predicted Emotion:\", emotion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTCn1qsG2CYd",
        "outputId": "b6866c02-5c41-42fa-8bf1-1035878df572"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-617288029.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: fearful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YcbN_CNN3mKS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}